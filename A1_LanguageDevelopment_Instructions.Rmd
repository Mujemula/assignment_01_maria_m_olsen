---
title: "Assignment 1 - Language development in autistic and neurotypical children"
output: html_document
date: "2022-08-15"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse,brms,tidybayes)
```

# Assignment 1  - Language development in autistic and neurotypical children

## Quick recap
Autism Spectrum Disorder is often related to language impairment. However, this phenomenon has rarely been empirically traced in detail: i) relying on actual naturalistic language production, ii) over extended periods of time.

We therefore videotaped circa 30 kids with ASD and circa 30 comparison kids (matched by linguistic performance at visit 1) for ca. 30 minutes of naturalistic interactions with a parent. We repeated the data collection 6 times per kid, with 4 months between each visit. We transcribed the data and counted: 
i) the amount of words that each kid uses in each video. Same for the parent.
ii) the amount of unique words that each kid uses in each video. Same for the parent.
iii) the amount of morphemes per utterance (Mean Length of Utterance) displayed by each child in each video. Same for the parent. 

This data is in the file you prepared in the previous class, but you can also find it here:https://www.dropbox.com/s/d6eerv6cl6eksf3/data_clean.csv?dl=0


## The structure of the assignment

We will be spending a few weeks with this assignment. In particular, we will:

Part 1) simulate data in order to better understand the model we need to build, and to better understand how much data we would have to collect to run a meaningful study (precision analysis)

Part 2) analyze our empirical data and interpret the inferential results

Part 3) use your model to predict the linguistic trajectory of new children and assess the performance of the model based on that.

As you work through these parts, you will have to produce a written document (separated from the code) answering the following questions:

Q1 - Briefly describe your simulation process, its goals, and what you have learned from the simulation. Add at least a plot showcasing the results of the simulation. Make a special note on sample size considerations: how much data do you think you will need? what else could you do to increase the precision of your estimates?

Q2 - Briefly describe the empirical data and how they compare to what you learned from the simulation (what can you learn from them?). Briefly describe your model(s) and model quality. Report the findings: how does development differ between autistic and neurotypical children (N.B. remember to report both population and individual level findings)? which additional factors should be included in the model? Add at least one plot showcasing your findings.

Q3 - Given the model(s) from Q2, how well do they predict the data? Discuss both in terms of absolute error in training vs testing; and in terms of characterizing the new kids' language development as typical or in need of support.


Below you can find more detailed instructions for each part of the assignment.

## Part 1 - Simulating data

Before we even think of analyzing the data, we should make sure we understand the problem, and we plan the analysis. To do so, we need to simulate data and analyze the simulated data (where we know the ground truth).

In particular, let's imagine we have n autistic and n neurotypical children. We are simulating their average utterance length (Mean Length of Utterance or MLU) in terms of words, starting at Visit 1 and all the way to Visit 6.
In other words, we need to define a few parameters:
- average MLU for ASD (population mean) at Visit 1 and average individual deviation from that (population standard deviation)
- average MLU for TD (population mean) at Visit 1 and average individual deviation from that (population standard deviation)
- average change in MLU by visit for ASD (population mean) and average individual deviation from that (population standard deviation)
- average change in MLU by visit for TD (population mean) and average individual deviation from that (population standard deviation)
- an error term. Errors could be due to measurement, sampling, all sorts of noise. 

Note that this makes a few assumptions: population means are exact values; change by visit is linear (the same between visit 1 and 2 as between visit 5 and 6). This is fine for the exercise. In real life research, you might want to vary the parameter values much more, relax those assumptions and assess how these things impact your inference.


We go through the literature and we settle for some values for these parameters:
- average MLU for ASD and TD: 1.5 (remember the populations are matched for linguistic ability at first visit)
- average individual variability in initial MLU for ASD 0.5; for TD 0.3 (remember ASD tends to be more heterogeneous)
- average change in MLU for ASD: 0.4; for TD 0.6 (ASD is supposed to develop less)
- average individual variability in change for ASD 0.4; for TD 0.2 (remember ASD tends to be more heterogeneous)
- error is identified as 0.2

This would mean that on average the difference between ASD and TD participants is 0 at visit 1, 0.2 at visit 2, 0.4 at visit 3, 0.6 at visit 4, 0.8 at visit 5 and 1 at visit 6.

With these values in mind, simulate data, plot the data (to check everything is alright); and set up an analysis pipeline.
Remember the usual bayesian workflow:
- define the formula
- define the prior
- prior predictive checks
- fit the model
- model quality checks: traceplots, divergences, rhat, effective samples
- model quality checks: posterior predictive checks, prior-posterior update checks
- model comparison

Once the pipeline is in place, loop through different sample sizes to assess how much data you would need to collect. N.B. for inspiration on how to set this up, check the tutorials by Kurz that are linked in the syllabus.

BONUS questions for Part 1: what if the difference between ASD and TD was 0? how big of a sample size would you need? What about different effect sizes, and different error terms?

```{r}
#reading in data to plot it and see how it looks
clean_df_1 <- read.csv("data_clean.csv")


```
#note to self
make hist to look at the spread and see if it makes sense compared to the data there already is out there about the area that uou are researching in

```{r}
hist(rnorm(1e4,log(1.5),0.20))
```

#Sabrinas prior values
Mean Intercept-ASD: normal(0.41,0.05)
Mean Intercept SD-ASD: normal(0,0.41)

Mean Intercept–TD: normal(0.41,0.2)
Mean Intercept SD–TD: normal(0,0.22)

Mean Visit effect–ASD: normal(0,0.1)
Mean Visit effect SD–ASD: normal(0,0.06)

Mean Visit effect–TD: normal(0,0.6)
Mean Visit effect SD: normal(0,0.03)



#Part 1 - simulating data
```{r}
set.seed(1912)
n_2 <- 40
n_3 <- 50
n_4 <- 60
#Defining parameters 
n <- 30 #set to 50?
mu_asd <- log(1.5)
sigma_asd <- log(1.5)-log(1.5-0.5)
mu_td <- log(1.5)
sigma_td <- log(1.5)-log(1.5-0.3)

mu_visit_asd <- 0.15 #0.4/1.5 
sigma_visit_asd <-  0.1 #0.4*(0.4/1.5)

mu_visit_td <-  0.20 #0.6/1.5
sigma_visit_td <- 0.08  #0.2*(0.6/1.5)

visit <- 6
error <- 0.2

#Making a function for simulating data
s_d <- function(n, visit, mu_asd, mu_td, sigma_asd, sigma_td, error){
  s_df <- tibble(expand.grid(ID=seq(n),
                             Diag= c("ASD", "TD"),
                             Visit = seq(visit))) %>%  
    mutate(ID = ifelse(Diag == "TD", ID + (n*2), ID), 
           IndividualIntercept = NA, 
           IndividualSlope = NA, 
           MLU = NA)
  
  for (i in seq(s_df$ID)) {
    #Assigning individual intercept
    s_df$IndividualIntercept[s_df$ID == i & s_df$Diag == "ASD"] <- rnorm(1, mu_asd, sigma_asd)
    s_df$IndividualIntercept[s_df$ID == i & s_df$Diag == "TD"] <- rnorm(1, mu_td, sigma_td)
    
    #Assigning individual slope
    s_df$IndividualSlope[s_df$ID == i & s_df$Diag == "ASD"] <- rnorm(1, mu_visit_asd, sigma_visit_asd)
    s_df$IndividualSlope[s_df$ID == i & s_df$Diag == "TD"] <- rnorm(1, mu_visit_td, sigma_visit_td)
  }
  
  for (i in seq(nrow(s_df))){
  s_df$MLU[i] <- exp(rnorm(1, (s_df$IndividualIntercept[i] + s_df$IndividualSlope[i] * (s_df$Visit[i]-1)), error))
                  }
  
  
  
  return(s_df)
}

d <- s_d(n, visit, mu_asd, mu_td, sigma_asd, sigma_td, error)
d_40 <- s_d(n_2, visit, mu_asd, mu_td, sigma_asd, sigma_td, error)
d_50 <- s_d(n_3, visit, mu_asd, mu_td, sigma_asd, sigma_td, error)
d_60 <- s_d(n_4, visit, mu_asd, mu_td, sigma_asd, sigma_td, error)

#Visualizing data
ggplot(d, aes(Visit, MLU, color = Diag, group = ID)) + 
  theme_bw() + 
  geom_point() + 
  geom_line(alpha = 0.3)

```

- define the formula
- define the prior
- prior predictive checks
- fit the model
- model quality checks: traceplots, divergences, rhat, effective samples #presition analysis
- model quality checks: posterior predictive checks, prior-posterior update checks
- model comparison #cross validation

#Part 1 - defining the formula
```{r}
#Intercepts only model
MLU_f0 <- bf(MLU ~ 1)

#Find out what these models are!!
MLU_f1 <- bf(MLU ~ 0 + Diag)

#Interceot + slope
MLU_f2 <- bf(MLU ~ 0 + Diag + Diag:Visit)

#Interept + slope and varrying intercept and slope
MLU_f_3 <- bf(MLU ~ 0 + Diag + Diag:Visit
+ (1 + Visit|ID))
```

###text to help myself
What we now so far: we are trying to mesure/find the bedst model to describe the MLU for children with ASD and TD. Would think that their MLU increases for each visit as they learn new words and therefor say more pr. utterrance.

OK, so we have simulated the data and now starts the accual baysian. We need to find out which priors to set for each model, and we check the priors in prior-predictive-cheks to see how the distibution of the priors are compared to our acual data. 

After checking the priors we need to fit the acual model. We do this for each of our models to see what is best


#my prior values
Mean Intercept-ASD: normal(0.41,0.05)
Mean Intercept SD-ASD: normal(0,0.41)

Mean Intercept–TD: normal(0.41,0.2)
Mean Intercept SD–TD: normal(0,0.22)

Mean Visit effect–ASD: normal(0,0.15)
Mean Visit effect SD–ASD: normal(0,0.1)

Mean Visit effect–TD: normal(0,0.2)
Mean Visit effect SD: normal(0,0.08)


mu_asd <- log(1.5)
sigma_asd <- log(1.5)-log(1.5-0.5)
mu_td <- log(1.5)
sigma_td <- log(1.5)-log(1.5-0.3)

mu_visit_asd <- 0.15
sigma_visit_asd <-  0.1 

mu_visit_td <-  0.20 
sigma_visit_td <- 0.08  

#Making priors and checking them
```{r}
#Looking parameters for prior
get_prior(MLU_f1, 
          data = d, 
          family = lognormal)


get_prior(MLU_f2,
          data = d,
          family = lognormal)


get_prior(MLU_f_3,
          data = d,
          family = lognormal)
 


#making priors
MLU_f1_prior <- c(
  prior(normal(0.41, 0.41), class=b, coef= "DiagASD"),
  prior(normal(0.41, 0.22), class=b, coef= "DiagTD"),
  prior(normal(0, 2), class= sigma)
)

MLU_f2_prior <- c(
  prior(normal(0, 0.2), class=b, lb=0), #error and lb=lower boundries
  prior(normal(0.41, 0.41), class=b, coef= "DiagASD"),
  prior(normal(0.41, 0.22), class=b, coef= "DiagTD"),
  prior(normal(0.15, 0.1), class=b, coef= "DiagASD:Visit"),
  prior(normal(0.2, 0.08), class=b, coef= "DiagTD:Visit"),
  prior(normal(0, 0.2), class= sigma)
)

MLU_f3_prior <- c(
  prior(normal(0, 0.2), class=b, lb=0),
  prior(normal(0.41, 0.41), class=b, coef= "DiagASD"),
  prior(normal(0.41, 0.22), class=b, coef= "DiagTD"),
  prior(normal(0.15, 0.1), class=b, coef= "DiagASD:Visit"),
  prior(normal(0.2, 0.08), class=b, coef= "DiagTD:Visit"),
  prior(normal(0, 0.2), class=sd, coef= Intercept, group=ID), #allowing the intercept for each person to varriate with 40% (because of logscale)
  prior(normal(0, 0.1), class=sd, coef= Visit, group=ID), #slope to varriate with 20% for each person
  prior(normal(0, 0.2), class= sigma),
  prior(lkj(1), class= "cor") 
)

MLU_f1_prior_samp <- 
  brm(
    MLU_f1, 
    data = d,
    family = lognormal,
    prior = MLU_f1_prior,  
    sample_prior = "only", 
    iter = 2000,
    warmup = 500,
    backend = "cmdstanr",
    threads = threading(2),
    cores = 2,
    chains = 2,
    file = "MLU_f1_prior_samp",
    control = list(adapt_delta = 0.99, max_treedepth = 20))


MLU_f2_prior_samp <- 
  brm(
    MLU_f2, 
    data = d,
    family = lognormal,
    prior = MLU_f2_prior,  
    sample_prior = "only", 
    iter = 2000,
    warmup = 500,
    backend = "cmdstanr",
    threads = threading(2),
    cores = 2,
    chains = 2,
    file = "MLU_f2_prior_samp",
    control = list(adapt_delta = 0.99, max_treedepth = 20))


MLU_f3_prior_sam <- 
  brm(
    MLU_f_3, 
    data = d,
    family = lognormal,
    prior = MLU_f3_prior,  
    sample_prior = "only", 
    iter = 2000,
    warmup = 500,
    backend = "cmdstanr",
    threads = threading(2),
    cores = 2,
    chains = 2,
    file = "MLU_f3_prior_sam",
    control = list(adapt_delta = 0.99, max_treedepth = 20))


#pp checking the priors - could look better, but fine i guess
pp_check(MLU_f1_prior_samp, ndraws = 100)
pp_check(MLU_f2_prior_samp, ndraws = 100)
pp_check(MLU_f3_prior_sam, ndraws = 100)

```


#fitting the models
```{r}
MLU_f1_prior_posterior <- 
  brm(
    MLU_f1, 
    data = d,
    family = lognormal,
    prior = MLU_f1_prior,  
    sample_prior = T, 
    iter = 5000,
    warmup = 1000,
    backend = "cmdstanr",
    threads = threading(2),
    cores = 2,
    chains = 2,
    file = "MLU_f1_prior_posterior",
    control = list(adapt_delta = 0.99, max_treedepth = 20))


MLU_f2_prior_posterior <- 
  brm(
    MLU_f2, 
    data = d,
    family = lognormal,
    prior = MLU_f2_prior,  
    sample_prior = T, 
    iter = 5000,
    warmup = 1000,
    backend = "cmdstanr",
    threads = threading(2),
    cores = 2,
    chains = 2,
    file = "MLU_f2_prior_posterior",
    control = list(adapt_delta = 0.99, max_treedepth = 20))


MLU_f3_prior_posterior <- 
  brm(
    MLU_f_3, 
    data = d,
    family = lognormal,
    prior = MLU_f3_prior,  
    sample_prior = T, 
    iter = 5000,
    warmup = 1000,
    backend = "cmdstanr",
    threads = threading(2),
    cores = 2,
    chains = 2,
    file = "MLU_f3_prior_posterior",
    control = list(adapt_delta = 0.99, max_treedepth = 20))

pp_check(MLU_f1_prior_posterior, ndraws = 100)
pp_check(MLU_f2_prior_posterior, ndraws = 100)
pp_check(MLU_f3_prior_posterior, ndraws = 100)

```
#conditional effects (do we need this?)
```{r}
plot(conditional_effects(MLU_f1_prior_posterior), points = T)
plot(conditional_effects(MLU_f2_prior_posterior), points = T)
plot(conditional_effects(MLU_f3_prior_posterior), points = T)
```



#getting variables and drawing samples from posteriors
```{r}
#getting an overview of the parameters
variables(MLU_f1_prior_posterior)
variables(MLU_f2_prior_posterior)
variables(MLU_f3_prior_posterior)

#sampling from model and storing it
MLU_f1_pp_samp <- as_draws_df(MLU_f1_prior_posterior)
MLU_f2_pp_samp <- as_draws_df(MLU_f2_prior_posterior)
MLU_f3_pp_samp <- as_draws_df(MLU_f3_prior_posterior)

```



#Making prior_posterior update check
```{r}
#Plot the prior-posterior update Model 1:
ggplot(MLU_f1_pp_samp) +
  geom_density(aes(prior_b_DiagASD), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_DiagASD), fill="#FC4E07", color="black",alpha=0.6) + 
  labs(title = "Diagnosis ASD model 1")+
  theme_classic()

ggplot(MLU_f1_pp_samp) +
  geom_density(aes(prior_b_DiagTD), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_DiagTD), fill="#FC4E07", color="black",alpha=0.6) + 
  labs(title = "Diagnosis TD model 1")+
  theme_classic()

ggplot(MLU_f1_pp_samp) +
  geom_density(aes(prior_sigma), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(sigma), fill="#FC4E07", color="black",alpha=0.6) + 
  labs(title = "Sigma TD model 1")+
  theme_classic()


#Plot the prior-posterior update Model 2:
ggplot(MLU_f2_pp_samp) +
  geom_density(aes(prior_b_DiagASD), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_DiagASD), fill="#FC4E07", color="black",alpha=0.6) + 
  labs(title = "Diagnosis ASD model 2")+
  theme_classic()

ggplot(MLU_f2_pp_samp) +
  geom_density(aes(prior_b_DiagTD), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_DiagTD), fill="#FC4E07", color="black",alpha=0.6) + 
  labs(title = "Diagnosis TD model 2")+
  theme_classic()

ggplot(MLU_f2_pp_samp) +
  geom_density(aes(MLU_f2_pp_samp$'prior_b_DiagASD:Visit'), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(MLU_f2_pp_samp$'b_DiagASD:Visit'), fill="#FC4E07", color="black",alpha=0.6) + 
  labs(title = "Diagnosis:Visit ASD model 2")+
  theme_classic()

ggplot(MLU_f2_pp_samp) +
  geom_density(aes(MLU_f2_pp_samp$'prior_b_DiagTD:Visit'), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(MLU_f2_pp_samp$'b_DiagTD:Visit'), fill="#FC4E07", color="black",alpha=0.6) + 
  labs(title = "Diagnosis:Visit TD model 2")+
  theme_classic()

ggplot(MLU_f1_pp_samp) +
  geom_density(aes(prior_sigma), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(sigma), fill="#FC4E07", color="black",alpha=0.6) + 
  labs(title = "Sigma TD model 1")+
  theme_classic()




#Plot the prior-posterior update Model 3:
ggplot(MLU_f3_pp_samp) +
  geom_density(aes(prior_b_DiagASD), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_DiagASD), fill="#FC4E07", color="black",alpha=0.6) + 
  labs(title = "Diagnosis ASD model 3")+
  theme_classic()

ggplot(MLU_f3_pp_samp) +
  geom_density(aes(prior_b_DiagTD), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_DiagTD), fill="#FC4E07", color="black",alpha=0.6) + 
  labs(title = "Diagnosis TD model 3")+
  theme_classic()

ggplot(MLU_f3_pp_samp) +
  geom_density(aes(MLU_f3_pp_samp$'prior_b_DiagASD:Visit'), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(MLU_f3_pp_samp$'b_DiagASD:Visit'), fill="#FC4E07", color="black",alpha=0.6) + 
  labs(title = "Diagnosis:Visit ASD model 3")+
  theme_classic()

ggplot(MLU_f3_pp_samp) +
  geom_density(aes(MLU_f3_pp_samp$'prior_b_DiagTD:Visit'), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(MLU_f3_pp_samp$'b_DiagTD:Visit'), fill="#FC4E07", color="black",alpha=0.6) + 
  labs(title = "Diagnosis:Visit TD model 3")+
  theme_classic()

ggplot(MLU_f3_pp_samp) +
  geom_density(aes(prior_sd_ID__Intercept), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(sd_ID__Intercept), fill="#FC4E07", color="black",alpha=0.6) + 
  labs(title = "sd_ID__Intercept TD model 3")+
  theme_classic()

ggplot(MLU_f3_pp_samp) +
  geom_density(aes(prior_sd_ID__Visit), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(sd_ID__Visit), fill="#FC4E07", color="black",alpha=0.6) + 
  labs(title = "sd_ID__Visit model 3")+
  theme_classic()

ggplot(MLU_f3_pp_samp) +
  geom_density(aes(prior_cor_ID__Intercept__Visit), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(cor_ID__Intercept__Visit), fill="#FC4E07", color="black",alpha=0.6) + 
  labs(title = "cor_ID__Intercept__Visit model 3")+
  theme_classic() #not working, maybe not necessary

ggplot(MLU_f3_pp_samp) +
  geom_density(aes(prior_sigma), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(sigma), fill="#FC4E07", color="black",alpha=0.6) + 
  labs(title = "Sigma TD model 3")+
  theme_classic()

```
#Traceplots
```{r}
#tracplot er bare at skrive 
plot(MLU_f1_prior_posterior)
plot(MLU_f2_prior_posterior)
plot(MLU_f3_prior_posterior)
```

#Updating model based on samplesize
```{r}
#So we simulate new data with a different sample size (bigger), (and because it is the same seed it is the same simulations for the first 30 fx and then it just makes more). Then we update the posterior model based on the new data with bigger sample size. Now we can look at the bulk and tail values to see if they are better with this sample size (the bigger the better)
Posterior_n_40 <- 
  update(MLU_f_3, #the model 
         data= d_40, #the new simulated data
         seed =1912) #the same seed as before
#above doesn't work


#Making posterior with our samplesize being 40
MLU_f3_prior_posterior_n_40 <- 
  brm(
    MLU_f_3, 
    data = d_40,
    family = lognormal,
    prior = MLU_f3_prior,  
    sample_prior = T, 
    iter = 5000,
    warmup = 1000,
    backend = "cmdstanr",
    threads = threading(2),
    cores = 2,
    chains = 2,
    file = "MLU_f3_prior_posterior_n_40",
    control = list(adapt_delta = 0.99, max_treedepth = 20))

#Making posterior with sample size being 50
MLU_f3_prior_posterior_n_50 <- 
  brm(
    MLU_f_3, 
    data = d_50,
    family = lognormal,
    prior = MLU_f3_prior,  
    sample_prior = T, 
    iter = 5000,
    warmup = 1000,
    backend = "cmdstanr",
    threads = threading(2),
    cores = 2,
    chains = 2,
    file = "MLU_f3_prior_posterior_n_50",
    control = list(adapt_delta = 0.99, max_treedepth = 20))

#Making posterior with sample size being 60
MLU_f3_prior_posterior_n_60 <- 
  brm(
    MLU_f_3, 
    data = d_60,
    family = lognormal,
    prior = MLU_f3_prior,  
    sample_prior = T, 
    iter = 5000,
    warmup = 1000,
    backend = "cmdstanr",
    threads = threading(2),
    cores = 2,
    chains = 2,
    file = "MLU_f3_prior_posterior_n_60",
    control = list(adapt_delta = 0.99, max_treedepth = 20))

#making summary to see judge which sample size is best (based on the bulk/tail values)
summary(MLU_f3_prior_posterior_n_40)
summary(MLU_f3_prior_posterior_n_50)
summary(MLU_f3_prior_posterior_n_60)
```
#Notes on sample size
looking at the bulk values, it seems that the model with a sample size of 80 (40 for ASD and 40 for TD) is the best sample size as the bulkvalues has highest here (so the prior-posterior iterates more here, aka looks at "flere" different samples of prior-posteriors, and has therefor explored "flere" different results). I think this means that with a sample size of 40, our prior-posterior model can be more trusted (if the Post.Prob is good), and that this model is the most robust or something like that.

#looking at how good the models are (cross validation?)
```{r}
summary(MLU_f1_prior_posterior)
summary(MLU_f2_prior_posterior)
summary(MLU_f3_prior_posterior)

hypothesis(MLU_f1_prior_posterior, "DiagASD<0") #?
hypothesis(MLU_f2_prior_posterior, "DiagASD:Visit<DiagTD:Visit")
hypothesis(MLU_f3_prior_posterior)
```

#sensitivity check
Think we need to make one for each slope (ASD and TD), because we have/set different slopes for ASD and TD
(should we have keept the slope equal as Riccardo wrote this in the beginning that this was an assumption we made?)
doesn't make sense to look at it for the intercept, as this is a fixed value in real life. Only really makes sense to look at it for the slope, as that is what we are interested in examining aka the relation between the MLU and the visit (visit=time if you think about it)

#sensitivity for ASD (smart way, but just doesn't work for me, look next section)
```{r}
#code to loop through sd of slope prior:
ASD_prior_SD <- seq(0.05, 0.20, length.out = 16) #the SD's from 0.1-1.5 (gonna make a posterior with each sd)
ASD_priors <- MLU_f3_prior #my priors 

#create empty sets to store output of the loop for ASD:
posterior_prediction_ASD <- c()
posterior_prediction_ASD_lci <- c()
posterior_prediction_ASD_uci <- c()

#loop through making priors with different sd
for (i in seq(ASD_prior_SD)) {
  ASD_priors[4,] <- prior(normal(0.15, ASD_prior_SD[i]), class = b, coef= "DiagASD:Visit")
  #model_for_loop <- brm(
   # MLU_f_3,
   # data= d,
   # family = lognormal,
  #  prior = ASD_priors,
   # sample_prior = T,
  #  iter = 5000,
  #  warmup = 1000,
  #  backend = "cmdstanr",
  #  threads = threading(2),
  #  cores = 2,
  #  chains = 2,
  #  control = list(adapt_delta = 0.99, max_treedepth = 20)
  #)
    
  
#  posterior_predictions <- spread_draws(model_for_loop, b_DiagASD:Visit) #slope, so b_DiagASD:Visit
#  posterior_prediction_ASD[i] <- median(posterior_predictions$b_DiagASD:Visit)
#  posterior_prediction_ASD_lci[i] <- quantile(posterior_predictions$b_DiagASD:Visit, prob = 0.025) #lower boundy for 95% interval
#  posterior_prediction_ASD_uci[i] <- quantile(posterior_predictions$b_DiagASD:Visit, prob = 0.975) #upper boundry for 95% interval
}

#Making dataframe from values from loop
sensitivity_check_ASD <- data.frame(ASD_prior_SD, posterior_prediction_ASD, posterior_prediction_ASD_lci, posterior_prediction_ASD_uci) 

#visualizing the sensitivity plot
ggplot(data=sensitivity_check_ASD, aes(x=ASD_prior_SD, y=posterior_prediction_ASD)) +
  geom_point(size = 3) +
  geom_pointrange(ymin = posterior_prediction_ASD_lci, ymax = posterior_prediction_ASD_uci) + #pointrange is 95% interval (vertical lines for each dot)
  ylim(0.05, 0.25) + #range for the slope (y-aksis range)
  labs(x="Standard Deviation of Slope Prior", 
       y="Posterior Estimate for Slope", 
       title="Sensitivity analysis for multi-level model ASD") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5, size = 15),
        axis.title.x = element_text(size = 13),
        axis.text.y = element_text(size = 12),
        axis.text.x = element_text(size = 12),
        axis.title.y = element_text(size = 13))
view(ASD_priors)
```


#sensitivity check ASD the real one
```{r}
#My priors
ASD_priors <- MLU_f3_prior  

#create empty sets to store output of the loop for ASD:
posterior_prediction_ASD <- c()
posterior_prediction_ASD_lci <- c()
posterior_prediction_ASD_uci <- c()

#Making all the priors we want to check (aka just changing the sd)
sd_priors <- c(
  prior(normal(0.15, 0.05), class = b, coef= "DiagASD:Visit"),
  prior(normal(0.15, 0.06), class = b, coef= "DiagASD:Visit"),
  prior(normal(0.15, 0.07), class = b, coef= "DiagASD:Visit"),
  prior(normal(0.15, 0.08), class = b, coef= "DiagASD:Visit"),
  prior(normal(0.15, 0.09), class = b, coef= "DiagASD:Visit"),
  prior(normal(0.15, 0.10), class = b, coef= "DiagASD:Visit"),
  prior(normal(0.15, 0.11), class = b, coef= "DiagASD:Visit"),
  prior(normal(0.15, 0.12), class = b, coef= "DiagASD:Visit"),
  prior(normal(0.15, 0.13), class = b, coef= "DiagASD:Visit"),
  prior(normal(0.15, 0.14), class = b, coef= "DiagASD:Visit"),
  prior(normal(0.15, 0.15), class = b, coef= "DiagASD:Visit"),
  prior(normal(0.15, 0.16), class = b, coef= "DiagASD:Visit"),
  prior(normal(0.15, 0.17), class = b, coef= "DiagASD:Visit"),
  prior(normal(0.15, 0.18), class = b, coef= "DiagASD:Visit"),
  prior(normal(0.15, 0.19), class = b, coef= "DiagASD:Visit"),
  prior(normal(0.15, 0.20), class = b, coef= "DiagASD:Visit")
)

#loop through making priors with different sd
for (i in seq(1, 16)) {
  ASD_priors[4,] <- sd_priors[i,]
  model_for_loop <- brm(
    MLU_f_3,
    data= d,
    family = lognormal,
    prior = ASD_priors,
    sample_prior = T,
    iter = 5000,
    warmup = 1000,
    backend = "cmdstanr",
    threads = threading(2),
    cores = 2,
    chains = 2,
    control = list(adapt_delta = 0.99, max_treedepth = 20)
  )
    
  Model_for_loop_samp <- as_draws_df(model_for_loop)
  #posterior_predictions <- spread_draws(model_for_loop, b_DiagASD:Visit) #slope, so b_DiagASD:Visit
  posterior_predictions <- Model_for_loop_samp[,3]
  posterior_prediction_ASD[i] <- median(posterior_predictions$`b_DiagASD:Visit`)
  posterior_prediction_ASD_lci[i] <- quantile(posterior_predictions$`b_DiagASD:Visit`, prob = 0.025) #lower boundy for 95% interval
  posterior_prediction_ASD_uci[i] <- quantile(posterior_predictions$`b_DiagASD:Visit`, prob = 0.975) #upper boundry for 95% interval
}


#Making dataframe from values from loop
sensitivity_check_ASD <- data.frame(ASD_prior_SD, posterior_prediction_ASD, posterior_prediction_ASD_lci, posterior_prediction_ASD_uci) 

#visualizing the sensitivity plot
rubostness_check_n_30_asd <- ggplot(data=sensitivity_check_ASD, aes(x=ASD_prior_SD, y=posterior_prediction_ASD)) +
  geom_point(size = 3) +
  geom_pointrange(ymin = posterior_prediction_ASD_lci, ymax = posterior_prediction_ASD_uci) + #pointrange is 95% interval (vertical lines for each dot)
  ylim(0.05, 0.25) + #range for the slope (y-aksis range)
  labs(x="Standard Deviation of Slope Prior", 
       y="Posterior Estimate for Slope", 
       title="Sensitivity analysis for multi-level model ASD") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5, size = 15),
        axis.title.x = element_text(size = 13),
        axis.text.y = element_text(size = 12),
        axis.text.x = element_text(size = 12),
        axis.title.y = element_text(size = 13))

ggsave("rubostness_check_n_30_asd.png", plot=rubostness_check_n_30_asd)
view(sensitivity_check_ASD)

```



#estimates plot
```{r}
temp_re <- ranef(MLU_f3_prior_posterior)$ID
for (i in unique(d$ID)) {
  temp <-as.character(i)
  d$EstimatedIntercept[d$ID == i] <- temp_re[,,"Intercept"][temp,1]
  d$EstimatedIntercept_low[d$ID == i] <- temp_re[,,"Intercept"][temp,3]
  d$EstimatedIntercept_high[d$ID == i] <- temp_re[,,"Intercept"][temp,4]
  d$EstimatedSlope[d$ID == i] <- temp_re[,,"Visit"][temp,1]
  d$EstimatedSlope_low[d$ID == i] <- temp_re[,,"Visit"][temp,3]
  d$EstimatedSlope_high[d$ID == i] <- temp_re[,,"Visit"][temp,4]
}

d1 <- d %>% subset(Visit==1) %>% 
  mutate(
    EstimatedIntercept = ifelse(Diag=="ASD",
                                EstimatedIntercept + 0.15,
                                EstimatedIntercept + 0.27),
    EstimatedIntercept_low = ifelse(Diag=="ASD",
                                EstimatedIntercept_low + 0.15,
                                EstimatedIntercept_low + 0.27),
    EstimatedIntercept_high = ifelse(Diag=="ASD",
                                EstimatedIntercept_high + 0.15,
                                EstimatedIntercept_high + 0.27),
    
    
    EstimatedSlope = ifelse(Diag=="ASD",
                                EstimatedSlope + 0.15,
                                EstimatedSlope + 0.19),
    EstimatedSlope_low = ifelse(Diag=="ASD",
                                EstimatedSlope_low + 0.15,
                                EstimatedSlope_low + 0.19),
    EstimatedSlope_high = ifelse(Diag=="ASD",
                                EstimatedSlope_high + 0.15,
                                EstimatedSlope_high + 0.19)
    
  )



Estimated_intercept <- ggplot(d1)+
  geom_pointrange(aes(x=as.numeric(as.factor(ID)),y=EstimatedIntercept,
                      ymin=EstimatedIntercept_low,ymax=EstimatedIntercept_high,
                      color = Diag),alpha=0.3) +
  geom_point(aes(x=as.numeric(as.factor(ID)),y=IndividualIntercept))+
  xlab("Precision of estimates by child")+
  ylab("Estimated intercept")


Estimated_slope <- ggplot(d1)+
  geom_pointrange(aes(x=as.numeric(as.factor(ID)),y=EstimatedSlope,
                      ymin=EstimatedSlope_low,ymax=EstimatedSlope_high,
                      color = Diag),alpha=0.3) +
  geom_point(aes(x=as.numeric(as.factor(ID)),y=IndividualSlope))+
  xlab("Precision of estimates by child")+
  ylab("Estimated slope")

Estimates_plot <- grid.arrange(Estimated_intercept, Estimated_slope)

ggsave("estimates_plot.png", Estimates_plot)
```


#precission analysis
```{r}
#set.seed(1912)
n_1 <- 30
n_2 <- 50
n_3 <- 70

#Defining parameters 
mu_asd <- log(1.5)
sigma_asd <- log(1.5)-log(1.5-0.5)
mu_td <- log(1.5)
sigma_td <- log(1.5)-log(1.5-0.3)

mu_visit_asd <- 0.15 #0.4/1.5 
sigma_visit_asd <-  0.1 #0.4*(0.4/1.5)

mu_visit_td <-  0.20 #0.6/1.5
sigma_visit_td <- 0.08  #0.2*(0.6/1.5)

visit <- 6
error <- 0.2

#Making a function for simulating data
s_pd <- function(n, seed){
  set.seed(seed)
  pd <- tibble(expand.grid(ID=seq(n),
                             Diag= c("ASD", "TD"),
                             Visit = seq(visit))) %>%  
    mutate(ID = ifelse(Diag == "TD", ID + (n*2), ID), 
           IndividualIntercept = NA, 
           IndividualSlope = NA, 
           MLU = NA)
  
  for (i in seq(pd$ID)) {
    #Assigning individual intercept
    pd$IndividualIntercept[pd$ID == i & pd$Diag == "ASD"] <- rnorm(1, mu_asd, sigma_asd)
    pd$IndividualIntercept[pd$ID == i & pd$Diag == "TD"] <- rnorm(1, mu_td, sigma_td)
    
    #Assigning individual slope
    pd$IndividualSlope[pd$ID == i & pd$Diag == "ASD"] <- rnorm(1, mu_visit_asd, sigma_visit_asd)
    pd$IndividualSlope[pd$ID == i & pd$Diag == "TD"] <- rnorm(1, mu_visit_td, sigma_visit_td)
  }
  
  for (i in seq(nrow(pd))){
  pd$MLU[i] <- exp(rnorm(1, (pd$IndividualIntercept[i] + pd$IndividualSlope[i] * (pd$Visit[i]-1)), error))
                  }
  
  
  
  return(pd)
}
```


#presision analysis
```{r}


# how many simulations would you like?
n_sim <- 2

# this will help us track time
t1 <- Sys.time()

# here's the main event!
m3 <-tibble(seed = 1:n_sim) %>%
  mutate(d = map(seed, s_pd, n = 30)) %>%
  mutate(fit = map2(d, seed, ~update(MLU_f3_prior_posterior, newdata = .x, seed = .y,iter=1000)))


t2 <- Sys.time()

t2 - t1

parameters <-
  m3 %>% 
  mutate(DiagASD = map(fit, ~ fixef(.) %>% 
                           data.frame() %>% 
                           rownames_to_column("parameter"))) %>% 
  unnest(DiagASD)

#parameters %>% 
 # select(-d, -fit) %>% 
 # filter(parameter == "DiagASD") %>% 
 # head()

head(parameters)

#Slope ASD
parameters_ASD_slope <- parameters %>% 
  filter(parameter=="DiagASD:Visit")

head(parameters_ASD_slope)

#Slope TD
parameters_TD_slope <- parameters %>% 
  filter(parameter=="DiagTD:Visit")

#Intercept ASD
parameters_ASD_intercept <- parameters %>% 
  filter(parameter=="DiagASD")

#Intercept TD
parameters_TD_intercept <- parameters %>% 
  filter(parameter=="DiagTD")


#making a plot of precession Slope ASD
samp_size_analysis_n30_parameters_ASD_slope %>% 
  ggplot(aes(x = seed, y = Estimate, ymin = Q2.5, ymax = Q97.5)) +
  geom_hline(yintercept = c(0, .5), color = "white") +
  geom_pointrange(fatten = 1/2) +
  labs(x = "seed",
       y = "DiagASD:Visit")

#making a plot of precession Slope TD
parameters_TD_slope %>% 
  ggplot(aes(x = seed, y = Estimate, ymin = Q2.5, ymax = Q97.5)) +
  geom_hline(yintercept = c(0, .5), color = "white") +
  geom_pointrange(fatten = 1/2) +
  labs(x = "seed",
       y = "DiagTD:Visit")

#making a plot of precession Intercept ASD (but dont need)
#parameters_ASD_intercept %>% 
#  ggplot(aes(x = seed, y = Estimate, ymin = Q2.5, ymax = Q97.5)) +
#  geom_hline(yintercept = c(0, .5), color = "white") +
#  geom_pointrange(fatten = 1/2) +
#  labs(x = "seed",
#       y = "DiagASD")

#making a plot of precession Intercept TD (but dont need)
#parameters_TD_intercept %>% 
#  ggplot(aes(x = seed, y = Estimate, ymin = Q2.5, ymax = Q97.5)) +
#  geom_hline(yintercept = c(0, .5), color = "white") +
#  geom_pointrange(fatten = 1/2) +
#  labs(x = "seed",
#       y = "DiagTD")

```


```{r}
sim_d <- function(seed,n){
  set.seed(seed)
  
   s_df <- tibble(expand.grid(ID=seq(n), 
                           Diag= c("ASD", "TD"), 
                           Visit = seq(visit)),
   IndivdualIntercept = as.numeric(0),
   IndividualSlope = as.numeric(0),
   MLU = as.numeric(0))

s_df <- s_df %>% 
  mutate(ID = ifelse(Diag == "TD", ID + (n*2), ID))



  for (i in seq(s_df$ID)) {
    s_df$IndividualIntercept[s_df$ID == i & s_df$Diag == "ASD"] <- rnorm(1, mu_asd, sigma_asd)
    s_df$IndividualIntercept[s_df$ID == i & s_df$Diag == "TD"] <- rnorm(1, mu_td, sigma_td)

    s_df$IndividualSlope[s_df$ID == i & s_df$Diag == "ASD"] <- rnorm(1, mu_visit_asd, sigma_visit_asd)
    s_df$IndividualSlope[s_df$ID == i & s_df$Diag == "TD"] <- rnorm(1, mu_visit_td, sigma_visit_td)
  }

  for (i in seq(nrow(s_df))){
  s_df$MLU[i] <- exp(rnorm(1, (s_df$IndividualIntercept[i] + s_df$IndividualSlope[i] * (s_df$Visit[i]-1)), error))
                  }

  return(s_df)
}

```


```{r}


# how many simulations would you like?
n_sim <- 2

# this will help us track time
t1 <- Sys.time()

# here's the main event!
m3 <-tibble(seed = 1:n_sim) %>%
mutate(s_df = map(seed, sim_d, n = 30)) %>%
mutate(fit = map2(s_df, seed, ~update(MLU_model3_posterior, newdata = .x, seed = .y,iter=1000)))


t2 <- Sys.time()

t2 - t1
```




#notes for me again
So i think this is the workflow - making model, making posteriors that fit the data and checking them before making a posterior, making the posterior, then checking if the model lerned something by making the prior-posterior update check for the parametors of interest, then looking at the summary to see the 95% interval to see how confident our model is. repeat this for the different model, exploring which priors are best for each model, and in the end compare each model to eachother.

What needs to be found out? Which distribution we should use!!!!! NOT Gaussian. 
But a little different workflow when predictors are added (aka not only intercept model) - do rubostness check. But kust look in the Workshop part 3.


# Part 2 - Strong in the Bayesian ken, you are now ready to analyse the actual data

- Describe your sample (n, age, gender, clinical and cognitive features of the two groups) and critically assess whether the groups (ASD and TD) are balanced. Briefly discuss whether the data is enough given the simulations in part 1.
- Describe linguistic development (in terms of MLU over time) in TD and ASD children (as a function of group). Discuss the difference (if any) between the two groups.
- Describe individual differences in linguistic development: do all kids follow the same path? Are all kids reflected by the general trend for their group?

- Include additional predictors in your model of language development (N.B. not other indexes of child language: types and tokens, that'd be cheating). Identify the best model, by conceptual reasoning, model comparison or a mix. Report the model you choose (and name its competitors, if any) and discuss why it's the best model.

```{r}

```


Part 3 - From explanation to prediction

N.B. There are several datasets for this exercise, so pay attention to which one you are using!

1. The (training) dataset from last time (the awesome one you produced :-) ).
2. The (test) datasets on which you can test the models from last time:
* Demographic and clinical data: https://www.dropbox.com/s/ra99bdvm6fzay3g/demo_test.csv?dl=1
* Utterance Length data: https://www.dropbox.com/s/uxtqqzl18nwxowq/LU_test.csv?dl=1
* Word data: https://www.dropbox.com/s/1ces4hv8kh0stov/token_test.csv?dl=1

Relying on the model(s) you trained in part 2 of the exercise, create predictions for the test set and assess how well they do compared to the actual data.

- Discuss the differences in performance of your model in training and testing data. Is the model any good?
- Let's assume you are a speech therapy clinic. You want to assess whether the kids in your test sample will have a typical (like a TD) development, or they will have a worse one, in which case they should get speech therapy support. What do your predictions tell you about that? Which kids would you provide therapy for? Is the model any good?

```{r}


```

